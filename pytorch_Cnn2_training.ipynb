{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3736.378396,
      "end_time": "2021-04-21T09:51:55.964848",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-04-21T08:49:39.586452",
      "version": "2.3.2"
    },
    "colab": {
      "name": "pytorch-Cnn2-training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibreza/Emotion-Recognition-from-Multi-Channel-EEG-Signals/blob/main/pytorch_Cnn2_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-04-21T08:49:44.633889Z",
          "iopub.status.busy": "2021-04-21T08:49:44.633240Z",
          "iopub.status.idle": "2021-04-21T08:49:49.756761Z",
          "shell.execute_reply": "2021-04-21T08:49:49.757741Z"
        },
        "papermill": {
          "duration": 5.139622,
          "end_time": "2021-04-21T08:49:49.758038",
          "exception": false,
          "start_time": "2021-04-21T08:49:44.618416",
          "status": "completed"
        },
        "tags": [],
        "id": "sunset-slovenia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7d60de-24ef-48a6-a3ce-1ec14721ea80"
      },
      "source": [
        "# from google.colab import drive\n",
        "import pickle as pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "from sklearn import preprocessing\n",
        "from scipy.signal import butter, lfilter\n",
        "import sklearn\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "torch.manual_seed(13)"
      ],
      "id": "sunset-slovenia",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd6d63a84b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slmODywDPSay",
        "outputId": "969bfc1a-68df-449f-9a3d-e22b446f5d31"
      },
      "id": "slmODywDPSay",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-21T08:49:49.785699Z",
          "iopub.status.busy": "2021-04-21T08:49:49.785028Z",
          "iopub.status.idle": "2021-04-21T08:49:49.788042Z",
          "shell.execute_reply": "2021-04-21T08:49:49.788523Z"
        },
        "papermill": {
          "duration": 0.020486,
          "end_time": "2021-04-21T08:49:49.788700",
          "exception": false,
          "start_time": "2021-04-21T08:49:49.768214",
          "status": "completed"
        },
        "tags": [],
        "id": "vital-senior"
      },
      "source": [
        "input_height = 9\n",
        "input_width = 9\n",
        "input_channel_num = 4\n",
        "# conv_fuse = \"plus\"\n",
        "\n",
        "# conv_1_shape = '4*4*1*16'\n",
        "# pool_1_shape = 'None'\n",
        "\n",
        "# # conv_2_shape = 'None'\n",
        "# conv_2_shape = '4*4*1*32'\n",
        "# pool_2_shape = 'None'\n",
        "\n",
        "# # conv_3_shape = 'None'\n",
        "# conv_3_shape = '4*4*1*64'\n",
        "# pool_3_shape = 'None'\n",
        "\n",
        "# conv_4_shape = '1*1*128*4'\n",
        "# pool_4_shape = 'None'\n",
        "\n",
        "time_step = 1\n",
        "window_size = 1\n",
        "# convolution full connected parameter\n",
        "fc_size = 1024\n",
        "\n",
        "dropout_prob = 0.5\n",
        "np.random.seed(3)\n",
        "\n",
        "calibration = 'N'\n",
        "norm_type = '2D'\n",
        "regularization_method = 'dropout'\n",
        "enable_penalty = True"
      ],
      "id": "vital-senior",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-21T08:49:49.817361Z",
          "iopub.status.busy": "2021-04-21T08:49:49.816685Z",
          "iopub.status.idle": "2021-04-21T08:49:49.823018Z",
          "shell.execute_reply": "2021-04-21T08:49:49.823902Z"
        },
        "papermill": {
          "duration": 0.026245,
          "end_time": "2021-04-21T08:49:49.824052",
          "exception": false,
          "start_time": "2021-04-21T08:49:49.797807",
          "status": "completed"
        },
        "tags": [],
        "id": "residential-anaheim"
      },
      "source": [
        "arousal_key = \"arousal_labels\"\n",
        "valence_key = \"valence_labels\"\n",
        "\n",
        "# def minus(item):\n",
        "#     return item-1\n",
        "\n",
        "def construct_data(input_file, arousal_or_valence=None, bands=[0, 1, 2, 3]):\n",
        "    input_channel_num = len(bands) * time_step\n",
        "\n",
        "    dataset_dir = '/content/drive/MyDrive/DEAP_3D//DE3D_'\n",
        "    ###load training set\n",
        "    print(\"loading \",dataset_dir+input_file,\".mat\")\n",
        "    data_file = sio.loadmat(dataset_dir+input_file+\".mat\")\n",
        "\n",
        "\n",
        "    cnn_datasets = data_file[\"data\"]\n",
        "\n",
        "    #start\n",
        "    arousal_labels = data_file[arousal_key]\n",
        "    valence_labels = data_file[valence_key]\n",
        "\n",
        "    arousal_labels = np.where(arousal_labels == 1, 2, arousal_labels)\n",
        "\n",
        "    curr_labels = np.add(arousal_labels, valence_labels)\n",
        "\n",
        "    # 0 = LALV, 1 = LAHV, 2 = HALV, 3 = HAHV\n",
        "    labels = curr_labels[0]\n",
        "\n",
        "    # print('labels: ', np.unique(labels, return_counts= True))\n",
        "\n",
        "    cnn_datasets = cnn_datasets.transpose(0,2,3,1)\n",
        "\n",
        "    cnn_datasets = cnn_datasets[:,:,:,bands]\n",
        "\n",
        "    cnn_datasets = cnn_datasets.reshape(len(cnn_datasets)//time_step, window_size,input_height,input_width,input_channel_num)\n",
        "\n",
        "    index = np.array(range(0, len(labels)))\n",
        "    np.random.shuffle(index)\n",
        "\n",
        "    cnn_datasets   = cnn_datasets[index].reshape((-1, 4, 9, 9))\n",
        "    labels  = labels[index]\n",
        "\n",
        "    return cnn_datasets, labels  "
      ],
      "id": "residential-anaheim",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetGenerator(Dataset):\n",
        "    def __init__(self, data_X, data_y):\n",
        "        self.data = data_X\n",
        "        self.labels = data_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inst = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        return inst, label"
      ],
      "metadata": {
        "id": "wgEwtTAPP9-h"
      },
      "id": "wgEwtTAPP9-h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CnnModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, (3, 3), 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, (3, 3), 1, 1)\n",
        "        # self.conv3 = nn.Conv2d(64, 32, (3, 3), 1, 1)\n",
        "        # self.conv4 = nn.Conv2d(128, 64, (1, 1))\n",
        "        self.fc1 = nn.Linear(64 * 9 * 9, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 4)\n",
        "        # self.fc3 = nn.Linear(256, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # x = F.relu(self.conv3(x))\n",
        "        # x = F.relu(self.conv4(x))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.relu(self.fc2(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CnnModel()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YeG4-dTyRAw",
        "outputId": "7132692d-ccdc-4d84-f378-422861ca587d"
      },
      "id": "8YeG4-dTyRAw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnModel(\n",
              "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=5184, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "\n",
        "    confusion_matrix = torch.zeros(4, 4)\n",
        "    with torch.no_grad():  \n",
        "      for t, p in zip(y_test.view(-1), y_pred_tags.view(-1)):\n",
        "            confusion_matrix[t.long(), p.long()] += 1\n",
        "    \n",
        "    acc = round(acc.item() * 100, 2)\n",
        "    \n",
        "    return acc, confusion_matrix"
      ],
      "metadata": {
        "id": "nkRsEbkS8mSq"
      },
      "id": "nkRsEbkS8mSq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = LALV, 1 = LAHV, 2 = HALV, 3 = HAHV\n",
        "label_mapping = {0: 'LALV', 1: 'LAHV', 2: 'HALV', 3: 'HAHV'}\n",
        "def report_result(best_model, data_X, data_y, label):\n",
        "  print('\\n',label,'\\n----------------\\n')\n",
        "  nb_classes = 4\n",
        "  data_y_hat = best_model.forward(data_X)\n",
        "  data_acc, confusion_matrix = multi_acc(data_y_hat, data_y)\n",
        "  print('****** mean classification accuracy: ', round(data_acc, 2), '% ******')\n",
        "  # print(confusion_matrix)\n",
        "  print('\\n Accuracy per class\\n ---------------')\n",
        "  acc_per_class = np.array(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
        "  for i in range(len(acc_per_class)):\n",
        "    print(label_mapping[i], ': ', round(acc_per_class[i]*100, 2), '%')\n",
        "  print('****** mean per class accuracy: ', round(np.mean(acc_per_class)*100, 2),'% ******\\n')"
      ],
      "metadata": {
        "id": "ibZ6tgoXDMqc"
      },
      "id": "ibZ6tgoXDMqc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = LALV, 1 = LAHV, 2 = HALV, 3 = HAHV\n",
        "label_mapping = {0: 'LALV', 1: 'LAHV', 2: 'HALV', 3: 'HAHV'}\n",
        "def get_result(best_model, data_X, data_y, label):\n",
        "  ret = {}\n",
        "  nb_classes = 4\n",
        "  data_y_hat = best_model.forward(data_X)\n",
        "  data_acc, confusion_matrix = multi_acc(data_y_hat, data_y)\n",
        "  ret['acc'] = round(data_acc, 2)\n",
        "  acc_per_class = np.array(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
        "  for i in range(len(acc_per_class)):\n",
        "    ret[label_mapping[i]] = round(acc_per_class[i]*100, 2)\n",
        "  ret['per_class_acc'] = round(np.mean(acc_per_class)*100, 2)\n",
        "\n",
        "  return ret"
      ],
      "metadata": {
        "id": "6JFZ2NVsYk_b"
      },
      "id": "6JFZ2NVsYk_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_X, train_y, valid_X, valid_y, batch=64, epoch_=50):\n",
        "    train_dataset = DatasetGenerator(train_X, train_y)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
        "\n",
        "    epochs = epoch_\n",
        "    loss_arr = []\n",
        "    acc_arr = []\n",
        "    val_loss_arr = []\n",
        "    val_acc_arr = []\n",
        "    best_val_acc = -1\n",
        "\n",
        "    for i in range(epochs):\n",
        "        for j, (batch_X, batch_y) in enumerate(dataloader): \n",
        "          y_hat = model.forward(batch_X)\n",
        "          loss = criterion(y_hat, batch_y)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()  \n",
        "        \n",
        "        y_hat = model.forward(train_X)\n",
        "        train_loss = criterion(y_hat, train_y)\n",
        "        train_acc = multi_acc(y_hat, train_y)[0]\n",
        "        valid_y_hat = model.forward(valid_X)\n",
        "        valid_loss = criterion(valid_y_hat, valid_y)\n",
        "        valid_acc = multi_acc(valid_y_hat, valid_y)[0]\n",
        "        \n",
        "        loss_arr.append(train_loss.detach())\n",
        "        acc_arr.append(train_acc)\n",
        "        val_loss_arr.append(valid_loss.detach())\n",
        "        val_acc_arr.append(valid_acc)\n",
        "        \n",
        "        if valid_acc > best_val_acc:\n",
        "          best_val_acc = valid_acc\n",
        "          torch.save(model.state_dict(), 'best-model-parameters.pt')\n",
        "          print(f'[Best Model Saved] Epoch: {i+1} Train Loss: {train_loss} Train Acc: {train_acc} Valid Loss: {valid_loss} Valid Acc: {valid_acc}')\n",
        "        else: #elif (i+1) % 10 == 0:\n",
        "          print(f'Epoch: {i+1} Train Loss: {loss} Train Acc: {train_acc} Valid Loss: {valid_loss} Valid Acc: {valid_acc}')\n",
        "        \n",
        "    return {'train_loss': loss_arr, 'val_loss': val_loss_arr}"
      ],
      "metadata": {
        "id": "Fx9fOFat86t7"
      },
      "id": "Fx9fOFat86t7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{0: 'LALV', 1: 'LAHV', 2: 'HALV', 3: 'HAHV'}\n",
        "acc_list = []\n",
        "pc_acc_list = []\n",
        "lalv_acc_list = []\n",
        "lahv_acc_list = []\n",
        "halv_acc_list = []\n",
        "hahv_acc_list = []\n",
        "\n",
        "for i in range(16):\n",
        "  sub_id = i + 1\n",
        "  print(\"**************** Process starting for subject no. \", sub_id, \"**************** \\n\")\n",
        "  if sub_id < 10:\n",
        "    input_file = 's0' + str(sub_id)\n",
        "  else:\n",
        "    input_file = 's' + str(sub_id)\n",
        "  model = CnnModel()\n",
        "  data, labels = construct_data(input_file)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "  train_X = torch.FloatTensor(X_train)\n",
        "  train_y = torch.LongTensor(y_train)\n",
        "  valid_X = torch.FloatTensor(X_val)\n",
        "  valid_y = torch.LongTensor(y_val)\n",
        "  test_X = torch.FloatTensor(X_test)\n",
        "  test_y = torch.LongTensor(y_test)\n",
        "  _ = train_model(model, train_X, train_y, valid_X, valid_y, epoch_=30)\n",
        "  best_model = CnnModel()\n",
        "  best_model.load_state_dict(torch.load('/content/best-model-parameters.pt'))\n",
        "  ret = get_result(best_model, test_X, test_y, 'Test Set')\n",
        "  acc_list.append(ret['acc'])\n",
        "  pc_acc_list.append(ret['per_class_acc'])\n",
        "  lalv_acc_list.append(ret['LALV'])\n",
        "  lahv_acc_list.append(ret['LAHV'])\n",
        "  halv_acc_list.append(ret['HALV'])\n",
        "  hahv_acc_list.append(ret['HAHV'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "IZFkYp81_FyD",
        "outputId": "64ca72de-77ef-41eb-dce9-f60ae80e48da"
      },
      "id": "IZFkYp81_FyD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** Process starting for subject no.  1 **************** \n",
            "\n",
            "loading  /content/drive/MyDrive/DEAP_3D//DE3D_s01 .mat\n",
            "[Best Model Saved] Epoch: 1 Train Loss: 1.2052161693572998 Train Acc: 42.22 Valid Loss: 1.2022020816802979 Valid Acc: 42.71\n",
            "[Best Model Saved] Epoch: 2 Train Loss: 1.0122952461242676 Train Acc: 59.65 Valid Loss: 1.0443788766860962 Valid Acc: 55.62\n",
            "[Best Model Saved] Epoch: 3 Train Loss: 0.8379133343696594 Train Acc: 67.43 Valid Loss: 0.8947916030883789 Valid Acc: 63.75\n",
            "[Best Model Saved] Epoch: 4 Train Loss: 0.689740777015686 Train Acc: 75.07 Valid Loss: 0.7693370580673218 Valid Acc: 69.79\n",
            "[Best Model Saved] Epoch: 5 Train Loss: 0.6518580317497253 Train Acc: 75.42 Valid Loss: 0.7592753171920776 Valid Acc: 70.42\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b8cc529b7a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCnnModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/best-model-parameters.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1f86f6fab988>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_X, train_y, valid_X, valid_y, batch, epoch_)\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_dict =   {'acc': acc_list,\n",
        "  'pc_acc': pc_acc_list,\n",
        "  'lalv': lalv_acc_list,\n",
        "  'lahv': lahv_acc_list,\n",
        "  'halv': halv_acc_list,\n",
        "  'hahv': hahv_acc_list}"
      ],
      "metadata": {
        "id": "qBWCdtQ6DDUU"
      },
      "id": "qBWCdtQ6DDUU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('result_cnn3.npy', result_dict)"
      ],
      "metadata": {
        "id": "AUMNMf-xhFGt"
      },
      "id": "AUMNMf-xhFGt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P02LSOPhRSki"
      },
      "id": "P02LSOPhRSki",
      "execution_count": null,
      "outputs": []
    }
  ]
}